{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Dependencies\" data-toc-modified-id=\"Dependencies-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Dependencies</a></span></li><li><span><a href=\"#Scrape-100-results\" data-toc-modified-id=\"Scrape-100-results-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Scrape 100 results</a></span></li><li><span><a href=\"#Get-n-pages-with-100-results\" data-toc-modified-id=\"Get-n-pages-with-100-results-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Get n pages with 100 results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete HLTV Scrape\n",
    "I am going to request all the matchpages, and save the column with all the info about the match as an html file on my Data drive (D:/).\n",
    "\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T12:11:19.972614Z",
     "start_time": "2018-10-27T12:11:18.806556Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape 100 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T12:21:36.947857Z",
     "start_time": "2018-10-27T12:21:36.931856Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapePage(soup):\n",
    "    sublists = soup.find_all(\"div\", {\"class\": \"results-sublist\"})\n",
    "    for sublist in sublists:\n",
    "        results = sublist.find_all(\"div\", {\"class\":\"result-con\"})\n",
    "        for result in results:\n",
    "            matchCode = result.find(\"a\", {\"class\":\"a-reset\"})['href'].split('/')[2]\n",
    "            url = \"https://www.hltv.org\" + result.find(\"a\", {\"class\":\"a-reset\"})['href']\n",
    "            innersoup = BeautifulSoup(requests.get(url).content, \"lxml\")\n",
    "            matchColumn = innersoup.find('div', {'class':'match-page'})\n",
    "            location = \"D:/CSGO_Matchpages/\"+matchCode+\".html\"\n",
    "            with open(location, \"w\") as file:\n",
    "                file.write(str(matchColumn.encode(\"utf-8\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get n pages with 100 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T14:35:36.022818Z",
     "start_time": "2018-10-27T12:26:32.114198Z"
    }
   },
   "outputs": [],
   "source": [
    "#Running time: 27s * n\n",
    "url = 'https://www.hltv.org/results?offset='\n",
    "n = 0\n",
    "for i in range(0,n):\n",
    "    time.sleep(1)  \n",
    "    scrapePage(BeautifulSoup(requests.get(url+str(i)+'00').content, \"lxml\"))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
